{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm, dummy, feature_selection\n",
    "\n",
    "# For stackoverflow uncomment following lines\n",
    "# csz = '18'\n",
    "# ml_in_file = \"/data/khodadaa/ml-exp/stack_feat/ml_in_{}.csv\".format(csz)\n",
    "# ml_out_file = \"/data/khodadaa/ml-exp/stack_feat/ml_out_{}_\".format(csz)\n",
    "\n",
    "# For wikipedia uncomment following lines\n",
    "csz = '2'\n",
    "# ml_in_file = \"/data/khodadaa/ml-exp/wiki/ml_in_{}.csv\".format(csz)\n",
    "ml_in_file = \"/data/khodadaa/ml-exp/wiki/ml_in_{}_vahid_features.csv\".format(csz)\n",
    "ml_out_file = \"/data/khodadaa/ml-exp/wiki/ml_out_{}_\".format(csz)\n",
    "\n",
    "#For inex uncomment following lines\n",
    "# csz = '24'\n",
    "# ml_in_file = \"/data/khodadaa/ml-exp/inex/inex_ml_in_{}.csv\".format(csz)\n",
    "# ml_out_file = \"/data/khodadaa/ml-exp/inex/inex_ml_out_{}_\".format(csz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_rel\n",
    "def t_test(data1, data2, alpha=0.05):\n",
    "    # compare samples\n",
    "    stat, p = ttest_rel(data1, data2)\n",
    "#     print('Statistics=%.3f, p=%.5f' % (stat, p))\n",
    "    # interpret    \n",
    "    if p > alpha:\n",
    "#         print('Same distributions (fail to reject H0)')\n",
    "        return True\n",
    "    else:\n",
    "#         print('Different distributions (reject H0)')\n",
    "        return False\n",
    "\n",
    "        \n",
    "def evaluation_results(y_true, y_pred, weight):\n",
    "    tn, fp, fn, tp = metrics.confusion_matrix(y_true, y_pred, sample_weight=weight).ravel() \n",
    "#     print(\"\\t  precision = %.3f\" % (tp / (tp + fp)))\n",
    "#     print(\"\\t  recall = %.3f\" % (tp / (tp + fn)))\n",
    "#     print('\\t  f1 score = %.3f' %(metrics.f1_score(y_true, y_pred)))\n",
    "#     print(\"\\t  negative predictive value= %.2f\" % (tn / (tn + fn)))\n",
    "#     print(\"\\t  true negative rate= %.2f\" % (tn / (tn + fp)))\n",
    "#     print(\"\\t  1s percentage = %.2f\" % (100 * np.sum(y_pred) / y_pred.shape[0]))\n",
    "    \n",
    "    ev = {'acc': (tp+tn)/(tp+tn+fp+fn),\n",
    "          'prec': tp/(tp+fp),\n",
    "          'rec': tp/(tp+fn),\n",
    "          'f1': metrics.f1_score(y_true, y_pred),\n",
    "          'NPV': tn/(tn+fn),\n",
    "          'TNR': tn/(tn+fp),          \n",
    "          '1-ratio': 100*np.sum(y_pred)/y_pred.shape[0]}\n",
    "    return ev\n",
    "\n",
    "def rank_features(model, X, y):\n",
    "    feature_selection.RFE(model, 1)\n",
    "    # create the RFE model and select 1 attributes    \n",
    "    rfe = feature_selection.RFE(model, 1)\n",
    "    rfe = rfe.fit(X, y)        \n",
    "    return rfe.ranking_\n",
    "    \n",
    "\n",
    "def get_mrr(y: pd.Series, rrgrps:dict, weights=None)-> float:\n",
    "    if weights is None:\n",
    "        weights = pd.Series(index=y.index, data=1.0)            \n",
    "    \n",
    "    (lb1, rrg1), (lb2, rrg2) = list(rrgrps.items())\n",
    "    y1inx, y2inx = y[y==lb1].index, y[y==lb2].index \n",
    "    \n",
    "    tot_wg = weights.loc[y.index].sum(axis=0)\n",
    "    summed_rr = (rrg1.loc[y1inx] * weights.loc[y1inx]).sum(axis=0) + \\\n",
    "                (rrg2.loc[y2inx] * weights.loc[y2inx]).sum(axis=0)\n",
    "    return summed_rr / tot_wg    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:\n",
      "['covered_c_bi_cmp', 'covered_c_bi_sub', 'covered_c_cmp', 'covered_c_sub', 'covered_t_bi_cmp', 'covered_t_bi_sub', 'covered_t_cmp', 'covered_t_sub', 'mean_df_c_bi_cmp', 'mean_df_c_bi_sub', 'mean_df_c_cmp', 'mean_df_c_sub', 'mean_df_t_bi_cmp', 'mean_df_t_bi_sub', 'mean_df_t_cmp', 'mean_df_t_sub', 'mean_mean_pop_c_bi_cmp', 'mean_mean_pop_c_bi_sub', 'mean_mean_pop_c_cmp', 'mean_mean_pop_c_sub', 'mean_mean_pop_t_bi_cmp', 'mean_mean_pop_t_bi_sub', 'mean_mean_pop_t_cmp', 'mean_mean_pop_t_sub', 'mean_min_pop_c_bi_cmp', 'mean_min_pop_c_bi_sub', 'mean_min_pop_c_cmp', 'mean_min_pop_c_sub', 'mean_min_pop_t_bi_cmp', 'mean_min_pop_t_bi_sub', 'mean_min_pop_t_cmp', 'mean_min_pop_t_sub', 'min_df_c_bi_cmp', 'min_df_c_bi_sub', 'min_df_c_cmp', 'min_df_c_sub', 'min_df_t_bi_cmp', 'min_df_t_bi_sub', 'min_df_t_cmp', 'min_df_t_sub', 'min_mean_pop_c_bi_cmp', 'min_mean_pop_c_bi_sub', 'min_mean_pop_c_cmp', 'min_mean_pop_c_sub', 'min_mean_pop_t_bi_cmp', 'min_mean_pop_t_bi_sub', 'min_mean_pop_t_cmp', 'min_mean_pop_t_sub', 'min_min_pop_c_bi_cmp', 'min_min_pop_c_bi_sub', 'min_min_pop_c_cmp', 'min_min_pop_c_sub', 'min_min_pop_t_bi_cmp', 'min_min_pop_t_bi_sub', 'min_min_pop_t_cmp', 'min_min_pop_t_sub', 'ql_c_bi_cmp', 'ql_c_bi_sub', 'ql_c_cmp', 'ql_c_sub', 'ql_t_bi_cmp', 'ql_t_bi_sub', 'ql_t_cmp', 'ql_t_sub', 'qll_c_bi_cmp', 'qll_c_bi_sub', 'qll_c_cmp', 'qll_c_sub', 'qll_t_bi_cmp', 'qll_t_bi_sub', 'qll_t_cmp', 'qll_t_sub', 'covered_c_bi_sub/covered_c_bi_cmp', 'covered_c_sub/covered_c_cmp', 'covered_t_bi_sub/covered_t_bi_cmp', 'covered_t_sub/covered_t_cmp', 'mean_df_c_bi_sub/mean_df_c_bi_cmp', 'mean_df_c_sub/mean_df_c_cmp', 'mean_df_t_bi_sub/mean_df_t_bi_cmp', 'mean_df_t_sub/mean_df_t_cmp', 'mean_mean_pop_c_bi_sub/mean_mean_pop_c_bi_cmp', 'mean_mean_pop_c_sub/mean_mean_pop_c_cmp', 'mean_mean_pop_t_bi_sub/mean_mean_pop_t_bi_cmp', 'mean_mean_pop_t_sub/mean_mean_pop_t_cmp', 'mean_min_pop_c_bi_sub/mean_min_pop_c_bi_cmp', 'mean_min_pop_c_sub/mean_min_pop_c_cmp', 'mean_min_pop_t_bi_sub/mean_min_pop_t_bi_cmp', 'mean_min_pop_t_sub/mean_min_pop_t_cmp', 'min_df_c_bi_sub/min_df_c_bi_cmp', 'min_df_c_sub/min_df_c_cmp', 'min_df_t_bi_sub/min_df_t_bi_cmp', 'min_df_t_sub/min_df_t_cmp', 'min_mean_pop_c_bi_sub/min_mean_pop_c_bi_cmp', 'min_mean_pop_c_sub/min_mean_pop_c_cmp', 'min_mean_pop_t_bi_sub/min_mean_pop_t_bi_cmp', 'min_mean_pop_t_sub/min_mean_pop_t_cmp', 'min_min_pop_c_bi_sub/min_min_pop_c_bi_cmp', 'min_min_pop_c_sub/min_min_pop_c_cmp', 'min_min_pop_t_bi_sub/min_min_pop_t_bi_cmp', 'min_min_pop_t_sub/min_min_pop_t_cmp', 'ql_c_bi_sub/ql_c_bi_cmp', 'ql_c_sub/ql_c_cmp', 'ql_t_bi_sub/ql_t_bi_cmp', 'ql_t_sub/ql_t_cmp', 'qll_c_bi_sub/qll_c_bi_cmp', 'qll_c_sub/qll_c_cmp', 'qll_t_bi_sub/qll_t_bi_cmp', 'qll_t_sub/qll_t_cmp']\n",
      "-------------------------------------------\n",
      "dum-u classifier ..\n",
      "-------------------------------------------\n",
      "dum-f classifier ..\n",
      "-------------------------------------------\n",
      "dum-s classifier ..\n",
      "-------------------------------------------\n",
      "dum-0 classifier ..\n",
      "-------------------------------------------\n",
      "dum-1 classifier ..\n",
      "-------------------------------------------\n",
      "ql classifier ..\n",
      "-------------------------------------------\n",
      "log classifier ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/stak/users/khodadaa/miniconda3/envs/db/lib/python3.6/site-packages/ipykernel_launcher.py:28: RuntimeWarning: invalid value encountered in long_scalars\n",
      "/nfs/stak/users/khodadaa/miniconda3/envs/db/lib/python3.6/site-packages/ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in long_scalars\n",
      "/nfs/stak/users/khodadaa/miniconda3/envs/db/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "log-bal classifier ..\n",
      "-------------------------------------------\n",
      "dum-u-swvc classifier ..\n",
      "-------------------------------------------\n",
      "dum-s-swvc classifier ..\n",
      "-------------------------------------------\n",
      "dum-0-swvc classifier ..\n",
      "-------------------------------------------\n",
      "dum-1-swvc classifier ..\n",
      "-------------------------------------------\n",
      "ql-swvc classifier ..\n",
      "-------------------------------------------\n",
      "log-swvc classifier ..\n",
      "-------------------------------------------\n",
      "dum-u-swbc classifier ..\n",
      "-------------------------------------------\n",
      "dum-s-swbc classifier ..\n",
      "-------------------------------------------\n",
      "dum-0-swbc classifier ..\n",
      "-------------------------------------------\n",
      "dum-1-swbc classifier ..\n",
      "-------------------------------------------\n",
      "ql-swbc classifier ..\n",
      "-------------------------------------------\n",
      "log-swbc classifier ..\n",
      "-------------------------------------------\n",
      "dum-u-swAr classifier ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/stak/users/khodadaa/miniconda3/envs/db/lib/python3.6/site-packages/ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/nfs/stak/users/khodadaa/miniconda3/envs/db/lib/python3.6/site-packages/ipykernel_launcher.py:28: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "dum-s-swAr classifier ..\n",
      "-------------------------------------------\n",
      "dum-0-swAr classifier ..\n",
      "-------------------------------------------\n",
      "dum-1-swAr classifier ..\n",
      "-------------------------------------------\n",
      "ql-swAr classifier ..\n",
      "-------------------------------------------\n",
      "log-swAr classifier ..\n",
      "-------------------------------------------\n",
      "dum-u-swnc classifier ..\n",
      "-------------------------------------------\n",
      "dum-s-swnc classifier ..\n",
      "-------------------------------------------\n",
      "dum-0-swnc classifier ..\n",
      "-------------------------------------------\n",
      "dum-1-swnc classifier ..\n",
      "-------------------------------------------\n",
      "ql-swnc classifier ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/stak/users/khodadaa/miniconda3/envs/db/lib/python3.6/site-packages/ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/nfs/stak/users/khodadaa/miniconda3/envs/db/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/nfs/stak/users/khodadaa/miniconda3/envs/db/lib/python3.6/site-packages/ipykernel_launcher.py:28: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "log-swnc classifier ..\n",
      "-------------------------------------------\n",
      "log-bal-swvc classifier ..\n",
      "-------------------------------------------\n",
      "log-bal-swbc classifier ..\n",
      "-------------------------------------------\n",
      "log-bal-swAr classifier ..\n",
      "-------------------------------------------\n",
      "log-bal-swnc classifier ..\n",
      "CPU times: user 1min 4s, sys: 2.18 s, total: 1min 6s\n",
      "Wall time: 9.36 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "TEST_SIZE = 0.33\n",
    "THREASHOLD = None\n",
    "FEATURES = None\n",
    "# FEATURES = ['ql_t_sub', 'ql_t_cmp']\n",
    "\n",
    "results = pd.DataFrame(columns=['features', '#feat', '|test|', '%badQ','thres', 'acc-tr',\n",
    "                                'acc', 'prec', 'rec', 'f1', 'TNR', 'NPV', '1-ratio',\n",
    "                                'mrr', 'mrr-max', 'mrr-bad', 'mrr-good'])\n",
    "\n",
    "def add_nonlinear_features(df):    \n",
    "    cols_sub = [c for c in df.columns if c[-4:] == '_sub']\n",
    "    cols_cmp = [c for c in df.columns if c[-4:] == '_cmp']    \n",
    "    for i, _ in enumerate(cols_sub):    \n",
    "        df[cols_sub[i]+'/'+cols_cmp[i]] = df[cols_sub[i]]/(df[cols_cmp[i]]+0.00000001)\n",
    "    return df\n",
    "\n",
    "\n",
    "def build_model(tr_X, tr_y, mod, cw=None, sw=None):        \n",
    "    if mod in ['dum-u', 'dum-f', 'dum-s']:        \n",
    "        strag = {'dum-u': 'uniform', 'dum-f': 'most_frequent', 'dum-s': 'stratified'}        \n",
    "        clf = dummy.DummyClassifier(strategy=strag[mod], random_state=1)\n",
    "    if mod in ['dum-0', 'dum-1']:\n",
    "        clf = dummy.DummyClassifier(strategy='constant', constant=int(mod[-1]))\n",
    "    if mod == 'log':\n",
    "        clf = linear_model.LogisticRegression(class_weight=cw, random_state=1)\n",
    "        \n",
    "    clf.fit(tr_X, tr_y, sample_weight=sw)\n",
    "    return clf\n",
    "\n",
    "\n",
    "in_df = pd.read_csv(ml_in_file)\n",
    "y = in_df['Y'].copy()\n",
    "X = in_df[in_df.columns.difference(['Query', 'Y', 'rr_al', 'rr_sb', 'TestViewCount'])].copy()\n",
    "bad_ix = in_df[in_df['rr_al'] > in_df['rr_sb']].index\n",
    "good_ix = in_df[in_df['rr_al'] <= in_df['rr_sb']].index\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "y = pd.Series(data=le.fit_transform(y), index=y.index)\n",
    "\n",
    "X = add_nonlinear_features(X)\n",
    "if FEATURES:\n",
    "    X = X.filter(FEATURES)\n",
    "\n",
    "feat = list(X.columns)\n",
    "print('Features:\\n%s' % (feat))\n",
    "\n",
    "train_x, test_x, train_y, test_y = model_selection.train_test_split(X, y, stratify=y, \\\n",
    "                                                                    test_size=TEST_SIZE, random_state=5)\n",
    "sc = preprocessing.MinMaxScaler()\n",
    "train_x = sc.fit_transform(train_x)\n",
    "test_x = sc.transform(test_x)\n",
    "\n",
    "\n",
    "def get_sample_weights(mod):\n",
    "    w = in_df['TestViewCount'].copy()        \n",
    "    \n",
    "    if mod == 'swbc':\n",
    "        tr0inx, tr1inx = train_y[train_y==0].index, train_y[train_y==1].index\n",
    "        ts0inx, ts1inx = test_y[test_y==0].index, test_y[test_y==1].index\n",
    "        tr0s, tr1s = w[tr0inx].sum(axis=0), w[tr1inx].sum(axis=0)\n",
    "        ts0s, ts1s = w[ts0inx].sum(axis=0), w[ts1inx].sum(axis=0)\n",
    "        w[tr0inx] /= tr0s\n",
    "        w[tr1inx] /= tr1s\n",
    "        w[ts0inx] /= ts0s\n",
    "        w[ts1inx] /= ts1s\n",
    "        \n",
    "    if mod == 'swAr':\n",
    "        tr0inx, tr1inx = train_y[train_y==0].index, train_y[train_y==1].index\n",
    "        tr0s, tr1s = w[tr0inx].sum(axis=0), w[tr1inx].sum(axis=0)\n",
    "        w[tr0inx] /= tr0s\n",
    "        w[tr1inx] /= tr1s\n",
    "    \n",
    "    if mod == 'swnc':\n",
    "        s0, s1 = w[y==0].sum(axis=0), w[y==1].sum(axis=0)    \n",
    "        w[y==0] /= s0\n",
    "        w[y==1] /= s1    \n",
    "    \n",
    "    return w.loc[train_y.index], w.loc[test_y.index]\n",
    "\n",
    "pred_df = pd.DataFrame(index=test_y.index)\n",
    "pred_df['Query'] = in_df.loc[test_y.index, 'Query']\n",
    "pred_df['TestViewCount'] = in_df.loc[test_y.index, 'TestViewCount']\n",
    "pred_df['rr_al'] = in_df.loc[test_y.index, 'rr_al']\n",
    "pred_df['rr_sb'] = in_df.loc[test_y.index, 'rr_sb']\n",
    "pred_df['true_y'] = test_y\n",
    "\n",
    "for mde in ['dum-u', 'dum-f', 'dum-s', 'dum-0', 'dum-1', 'ql', 'log', 'log-bal',\n",
    "            'dum-u-swvc', 'dum-s-swvc', 'dum-0-swvc', 'dum-1-swvc', 'ql-swvc', 'log-swvc',             \n",
    "            'dum-u-swbc', 'dum-s-swbc', 'dum-0-swbc', 'dum-1-swbc', 'ql-swbc', 'log-swbc',            \n",
    "            'dum-u-swAr', 'dum-s-swAr', 'dum-0-swAr', 'dum-1-swAr', 'ql-swAr', 'log-swAr',\n",
    "            'dum-u-swnc', 'dum-s-swnc', 'dum-0-swnc', 'dum-1-swnc', 'ql-swnc', 'log-swnc',\n",
    "            'log-bal-swvc', 'log-bal-swbc', 'log-bal-swAr', 'log-bal-swnc']:\n",
    "    m = mde\n",
    "    clf = None\n",
    "    clweight = None\n",
    "    fea_cnt = 0\n",
    "    print('-------------------------------------------')\n",
    "    print(m + \" classifier ..\")    \n",
    "    train_weights, test_weights = None, None\n",
    "    # set weight\n",
    "    if m[-5:] in ['-swvc', '-swnc', '-swbc', '-swAr']:        \n",
    "        train_weights, test_weights = get_sample_weights(m[-4:])\n",
    "        # train without sample_weights, test with sample_weights\n",
    "        if m in ['log-bal-swvc', 'log-bal-swbc', 'log-bal-swAr', 'log-bal-swnc']:\n",
    "            train_weights = None\n",
    "        m = m[:-5]\n",
    "    # set balanced labels\n",
    "    if m[-4:] == '-bal':\n",
    "        clweight = 'balanced'\n",
    "        m = m[:-4]\n",
    "    \n",
    "    if m[:2] == 'ql':\n",
    "        X_ql = X.loc[test_y.index, ['ql_t_sub', 'ql_t_cmp']]\n",
    "        pred_y = np.where(X_ql['ql_t_sub'] >= X_ql['ql_t_cmp'], 'sub', 'all')\n",
    "        pred_y = le.transform(pred_y)\n",
    "        fea_cnt = 2\n",
    "    else:\n",
    "        clf = build_model(train_x, train_y, mod=m, sw=train_weights, cw=clweight)        \n",
    "        pred_y = clf.predict(test_x)\n",
    "        fea_cnt = len(feat)\n",
    "    pred_y = pd.Series(data=pred_y, index=test_y.index)\n",
    "    \n",
    "    res = {'features': feat, '#feat': fea_cnt,  '|test|': TEST_SIZE, 'thres': THREASHOLD,\n",
    "           'acc-tr': None if  clf is None else clf.score(train_x, train_y, train_weights)}\n",
    "    res.update(evaluation_results(test_y, pred_y, test_weights))\n",
    "    \n",
    "    subL, allL = le.transform(['sub', 'all'])\n",
    "    rrg = {subL: in_df['rr_sb'], allL: in_df['rr_al']}\n",
    "    mrr = get_mrr(pred_y, rrg, weights=test_weights)\n",
    "    mrr_mx = get_mrr(test_y, rrg, weights=test_weights)    \n",
    "    res.update({'mrr': mrr, 'mrr-max': mrr_mx})\n",
    "    \n",
    "    # bad queries\n",
    "    bad_test_ix = test_y.index.intersection(bad_ix)\n",
    "    res['%badQ'] = (bad_test_ix.shape[0] / test_y.shape[0]) * 100.0\n",
    "    bad_rrg = {subL: in_df.loc[bad_test_ix, 'rr_sb'], allL: in_df.loc[bad_test_ix, 'rr_al']}    \n",
    "    bad_mrr = get_mrr(pred_y.loc[bad_test_ix], bad_rrg, weights=test_weights)\n",
    "    res['mrr-bad'] = bad_mrr\n",
    "    \n",
    "    # good queries\n",
    "    good_test_ix = test_y.index.intersection(good_ix)\n",
    "    good_rrg = {subL: in_df.loc[good_test_ix, 'rr_sb'], allL: in_df.loc[good_test_ix, 'rr_al']}    \n",
    "    good_mrr = get_mrr(pred_y.loc[good_test_ix], good_rrg, weights=test_weights)\n",
    "    res['mrr-good'] = good_mrr\n",
    "    \n",
    "    # rank features for logisitic regression\n",
    "    if mde == 'log-bal-swvc':        \n",
    "        feat_rankings = rank_features(clf, train_x, train_y)\n",
    "        feat_rankings = list(zip(feat_rankings, feat))\n",
    "        feat_rankings.sort()\n",
    "        res['features'] = str(feat_rankings)\n",
    "        \n",
    "    \n",
    "    results.loc[mde, :] = res\n",
    "    pred_df[mde] = pred_y\n",
    "\n",
    "results.to_csv(ml_out_file+'{}_evals.csv'.format(len(feat)))\n",
    "pred_df.to_csv(ml_out_file+'{}_predicts.csv'.format(len(feat)), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dum-s true_y Same distributions\n",
      "dum-s-swAr dum-s-swnc Same distributions\n",
      "dum-s-swAr dum-u Same distributions\n",
      "dum-s-swAr dum-u-swAr Same distributions\n",
      "dum-s-swAr dum-u-swbc Same distributions\n",
      "dum-s-swAr dum-u-swnc Same distributions\n",
      "dum-s-swAr dum-u-swvc Same distributions\n",
      "dum-s-swbc dum-s-swnc Same distributions\n",
      "dum-s-swbc dum-u Same distributions\n",
      "dum-s-swbc dum-u-swAr Same distributions\n",
      "dum-s-swbc dum-u-swbc Same distributions\n",
      "dum-s-swbc dum-u-swnc Same distributions\n",
      "dum-s-swbc dum-u-swvc Same distributions\n",
      "dum-s-swnc dum-u Same distributions\n",
      "dum-s-swnc dum-u-swAr Same distributions\n",
      "dum-s-swnc dum-u-swbc Same distributions\n",
      "dum-s-swnc dum-u-swnc Same distributions\n",
      "dum-s-swnc dum-u-swvc Same distributions\n"
     ]
    }
   ],
   "source": [
    "test_names = list(pred_df.columns.difference(['Query', 'TestViewCount', 'rr_al', 'rr_sb']))\n",
    "for i, m1 in enumerate(test_names):\n",
    "    for m2 in test_names[i+1:]:\n",
    "        if t_test(pred_df[m1], pred_df[m2]):\n",
    "            print(m1, m2, 'Same distributions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>%badQ</th>\n",
       "      <th>mrr-good</th>\n",
       "      <th>mrr-bad</th>\n",
       "      <th>mrr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dum-0-swvc</th>\n",
       "      <td>6.85216</td>\n",
       "      <td>0.226356</td>\n",
       "      <td>0.455406</td>\n",
       "      <td>0.239463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dum-1-swvc</th>\n",
       "      <td>6.85216</td>\n",
       "      <td>0.707002</td>\n",
       "      <td>0.0253723</td>\n",
       "      <td>0.667997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dum-u-swvc</th>\n",
       "      <td>6.85216</td>\n",
       "      <td>0.470672</td>\n",
       "      <td>0.249122</td>\n",
       "      <td>0.457994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ql-swvc</th>\n",
       "      <td>6.85216</td>\n",
       "      <td>0.658308</td>\n",
       "      <td>0.18329</td>\n",
       "      <td>0.631126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log-bal-swvc</th>\n",
       "      <td>6.85216</td>\n",
       "      <td>0.636354</td>\n",
       "      <td>0.298085</td>\n",
       "      <td>0.616997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                %badQ  mrr-good    mrr-bad       mrr\n",
       "dum-0-swvc    6.85216  0.226356   0.455406  0.239463\n",
       "dum-1-swvc    6.85216  0.707002  0.0253723  0.667997\n",
       "dum-u-swvc    6.85216  0.470672   0.249122  0.457994\n",
       "ql-swvc       6.85216  0.658308    0.18329  0.631126\n",
       "log-bal-swvc  6.85216  0.636354   0.298085  0.616997"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.loc[['dum-0-swvc', 'dum-1-swvc', 'dum-u-swvc', 'ql-swvc', 'log-bal-swvc'], ['%badQ','mrr-good', 'mrr-bad', 'mrr']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[(1, 'ql_t_bi_sub/ql_t_bi_cmp'), (2, 'min_mean_pop_t_bi_sub'), (3, 'qll_t_sub/qll_t_cmp'), (4, 'mean_mean_pop_t_bi_cmp'), (5, 'min_min_pop_t_bi_sub'), (6, 'min_mean_pop_t_sub'), (7, 'min_mean_pop_t_cmp'), (8, 'ql_c_bi_sub/ql_c_bi_cmp'), (9, 'mean_min_pop_t_sub'), (10, 'mean_df_c_cmp'), (11, 'mean_df_c_sub'), (12, 'min_df_t_bi_sub/min_df_t_bi_cmp'), (13, 'covered_c_bi_sub/covered_c_bi_cmp'), (14, 'min_df_c_cmp'), (15, 'covered_t_bi_sub'), (16, 'min_mean_pop_t_bi_cmp'), (17, 'min_min_pop_t_bi_cmp'), (18, 'mean_min_pop_t_bi_sub'), (19, 'ql_t_sub'), (20, 'min_df_t_cmp'), (21, 'mean_mean_pop_c_bi_sub'), (22, 'qll_t_bi_sub'), (23, 'qll_c_cmp'), (24, 'mean_min_pop_c_sub/mean_min_pop_c_cmp'), (25, 'min_df_c_bi_sub/min_df_c_bi_cmp'), (26, 'ql_c_sub/ql_c_cmp'), (27, 'mean_df_t_bi_sub/mean_df_t_bi_cmp'), (28, 'min_min_pop_t_bi_sub/min_min_pop_t_bi_cmp'), (29, 'mean_df_t_sub'), (30, 'mean_df_t_cmp'), (31, 'min_min_pop_t_sub'), (32, 'mean_min_pop_c_bi_sub'), (33, 'qll_c_sub/qll_c_cmp'), (34, 'covered_t_sub'), (35, 'mean_min_pop_c_cmp'), (36, 'min_min_pop_c_sub'), (37, 'mean_df_t_bi_sub'), (38, 'mean_df_c_bi_sub'), (39, 'min_df_c_sub/min_df_c_cmp'), (40, 'qll_t_cmp'), (41, 'mean_min_pop_c_bi_cmp'), (42, 'mean_df_c_bi_sub/mean_df_c_bi_cmp'), (43, 'mean_min_pop_t_cmp'), (44, 'mean_mean_pop_t_sub'), (45, 'min_min_pop_t_cmp'), (46, 'min_min_pop_c_cmp'), (47, 'min_df_t_sub/min_df_t_cmp'), (48, 'ql_c_sub'), (49, 'mean_df_t_bi_cmp'), (50, 'min_df_c_sub'), (51, 'min_mean_pop_c_sub'), (52, 'mean_min_pop_t_bi_sub/mean_min_pop_t_bi_cmp'), (53, 'min_min_pop_c_sub/min_min_pop_c_cmp'), (54, 'qll_t_bi_cmp'), (55, 'covered_c_cmp'), (56, 'covered_c_sub'), (57, 'qll_c_sub'), (58, 'mean_min_pop_c_bi_sub/mean_min_pop_c_bi_cmp'), (59, 'min_min_pop_c_bi_cmp'), (60, 'min_mean_pop_c_sub/min_mean_pop_c_cmp'), (61, 'min_mean_pop_t_bi_sub/min_mean_pop_t_bi_cmp'), (62, 'ql_t_sub/ql_t_cmp'), (63, 'min_min_pop_c_bi_sub'), (64, 'mean_mean_pop_t_cmp'), (65, 'min_df_t_sub'), (66, 'qll_t_bi_sub/qll_t_bi_cmp'), (67, 'min_min_pop_t_sub/min_min_pop_t_cmp'), (68, 'mean_min_pop_c_sub'), (69, 'covered_t_cmp'), (70, 'min_min_pop_c_bi_sub/min_min_pop_c_bi_cmp'), (71, 'ql_t_cmp'), (72, 'min_mean_pop_c_bi_cmp'), (73, 'covered_t_bi_sub/covered_t_bi_cmp'), (74, 'mean_mean_pop_c_sub/mean_mean_pop_c_cmp'), (75, 'min_mean_pop_c_bi_sub/min_mean_pop_c_bi_cmp'), (76, 'mean_mean_pop_c_bi_cmp'), (77, 'min_mean_pop_c_bi_sub'), (78, 'mean_df_c_sub/mean_df_c_cmp'), (79, 'mean_min_pop_t_bi_cmp'), (80, 'mean_mean_pop_t_bi_sub/mean_mean_pop_t_bi_cmp'), (81, 'qll_t_sub'), (82, 'qll_c_bi_sub'), (83, 'qll_c_bi_cmp'), (84, 'mean_df_t_sub/mean_df_t_cmp'), (85, 'mean_mean_pop_c_bi_sub/mean_mean_pop_c_bi_cmp'), (86, 'ql_t_bi_cmp'), (87, 'covered_c_bi_sub'), (88, 'mean_mean_pop_c_cmp'), (89, 'ql_c_cmp'), (90, 'mean_mean_pop_t_bi_sub'), (91, 'ql_c_bi_cmp'), (92, 'covered_c_sub/covered_c_cmp'), (93, 'mean_df_c_bi_cmp'), (94, 'mean_mean_pop_c_sub'), (95, 'min_mean_pop_t_sub/min_mean_pop_t_cmp'), (96, 'min_df_c_bi_sub'), (97, 'covered_t_bi_cmp'), (98, 'min_df_t_bi_sub'), (99, 'min_df_t_bi_cmp'), (100, 'mean_min_pop_t_sub/mean_min_pop_t_cmp'), (101, 'covered_c_bi_cmp'), (102, 'covered_t_sub/covered_t_cmp'), (103, 'min_df_c_bi_cmp'), (104, 'ql_c_bi_sub'), (105, 'ql_t_bi_sub'), (106, 'min_mean_pop_c_cmp'), (107, 'mean_mean_pop_t_sub/mean_mean_pop_t_cmp'), (108, 'qll_c_bi_sub/qll_c_bi_cmp')]\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.loc['log-bal-swvc', 'features']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>log</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dum</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A    B    C\n",
       "log  1   10  NaN\n",
       "dum  2  NaN   20"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add a new indexed row to a Dataframe from a dictionary \n",
    "df = pd.DataFrame(columns=['A', 'B', 'C'], dtype=int)\n",
    "df.loc['log', :] = {'A':1, 'B':10}\n",
    "df.loc['dum', :] = {'A':2, 'C':20}\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 4, 'C': 3, 'B': 2}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine two dictionaries\n",
    "d1 = {'A':1, 'C':3}\n",
    "d2 = {'B':2, 'A':4}\n",
    "d1.update(d2)\n",
    "d1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
