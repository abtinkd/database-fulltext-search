{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert 2 qid:13 1:2 2:0 3:2 ... --> {'rel': 2, 'qid': 13, 1:2, 2:0, 3:2, ...} then build a Dataframe based on it \n",
    "def split_fea_name_val(df: pd.DataFrame):\n",
    "    def func(c):\n",
    "        fe, val = c.split(':', 1)    \n",
    "        return \"{}: {}\".format(fe, val)\n",
    "    dict_df = df.apply(lambda x: ast.literal_eval(\"{{'rel': {}, 'qid': {}, {}}}\".format(\n",
    "        x[0], x[1].split(':',1)[1], ', '.join(x[2:].apply(lambda cl: func(cl))))), axis=1)\n",
    "    return pd.DataFrame(index=dict_df.index, data=list(dict_df.values))\n",
    "\n",
    "def adjust_features(df: pd.DataFrame, cols: list):\n",
    "    for i, v in enumerate(cols):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        df[v] = df[v].str.replace(str(v-1)+':', str(i-1)+':')\n",
    "    return df\n",
    "\n",
    "def sort_qid(df: pd.DataFrame):\n",
    "    df[['qid-str', 'qid']] = df[1].str.split(':', expand=True)\n",
    "    df['qid'] = df.qid.astype(int)\n",
    "\n",
    "    df.sort_values(by='qid', inplace=True)\n",
    "    df.drop(columns=['qid-str', 'qid'], inplace=True)\n",
    "    \n",
    "def split_X_y_qid(df: pd.DataFrame):\n",
    "    df = split_fea_name_val(df)\n",
    "    X = df[list(range(1,df.columns[-1]))]\n",
    "    y = df['rel']\n",
    "    qid = df['qid']\n",
    "    return X, y, qid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSLR-WEB data preparation - Sort data based on qid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold1 train (723412, 138)\n",
      "Split done!\n",
      "Fold1 vali (235259, 138)\n",
      "Split done!\n",
      "Fold1 test (241521, 138)\n",
      "Split done!\n",
      "Fold2 train (716683, 138)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-277-39dd00719e6c>\u001b[0m in \u001b[0;36msplit_X_y_qid\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msplit_X_y_qid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_fea_name_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rel'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-277-39dd00719e6c>\u001b[0m in \u001b[0;36msplit_fea_name_val\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"{}: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     dict_df = df.apply(lambda x: ast.literal_eval(\"{{'rel': {}, 'qid': {}, {}}}\".format(\n\u001b[0;32m----> 7\u001b[0;31m         x[0], x[1].split(':',1)[1], ', '.join(x[2:].apply(lambda cl: func(cl))))), axis=1)\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/db/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, broadcast, raw, reduce, args, **kwds)\u001b[0m\n\u001b[1;32m   4875\u001b[0m                         \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4876\u001b[0m                         \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4877\u001b[0;31m                         ignore_failures=ignore_failures)\n\u001b[0m\u001b[1;32m   4878\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4879\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_broadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/db/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_apply_standard\u001b[0;34m(self, func, axis, ignore_failures, reduce)\u001b[0m\n\u001b[1;32m   4931\u001b[0m                     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_agg_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4932\u001b[0m                     result = lib.reduce(values, func, axis=axis, dummy=dummy,\n\u001b[0;32m-> 4933\u001b[0;31m                                         labels=labels)\n\u001b[0m\u001b[1;32m   4934\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4935\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/src/reduce.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.reduce\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/src/reduce.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.Reducer.get_result\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-277-39dd00719e6c>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"{}: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     dict_df = df.apply(lambda x: ast.literal_eval(\"{{'rel': {}, 'qid': {}, {}}}\".format(\n\u001b[0;32m----> 7\u001b[0;31m         x[0], x[1].split(':',1)[1], ', '.join(x[2:].apply(lambda cl: func(cl))))), axis=1)\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/db/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   2556\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2557\u001b[0m             return self._constructor(mapped,\n\u001b[0;32m-> 2558\u001b[0;31m                                      index=self.index).__finalize__(self)\n\u001b[0m\u001b[1;32m   2559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2560\u001b[0m     def _reduce(self, op, name, axis=0, skipna=True, numeric_only=None,\n",
      "\u001b[0;32m~/miniconda3/envs/db/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    264\u001b[0m                                        raise_cast_failure=True)\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSingleBlockManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mgeneric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/db/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, block, axis, do_integrity_check, fastpath)\u001b[0m\n\u001b[1;32m   4363\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_integrity_check\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4365\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4366\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4367\u001b[0m                 raise ValueError(\"cannot create SingleBlockManager with more \"\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# output_postfix = 'reduced'\n",
    "bp, dirname = '/data/khodadaa/mslr/MSLR-WEB10K/', 'mslr-web10k'\n",
    "# bp, dirname = '/data/khodadaa/mslr/MSLR-WEB30K/', 'mslr-web30k'\n",
    "# bp, dirname = '/data/khodadaa/mslr/Gov/Feature_min/2003_hp_dataset/', '2003_hp_dataset'\n",
    "\n",
    "cols = None\n",
    "# cols = list(range(1,6)) #+ list(range(11,26)) + list(range(71,76)) + list(range(105, 132))\n",
    "# cols = [0, 1] + list(map(lambda x: x+1, keep))\n",
    "\n",
    "for fn in range(1,6):\n",
    "    fold = 'Fold' + str(fn)\n",
    "    npz_dict = {}\n",
    "    for gr in ['train', 'vali', 'test']:\n",
    "        df = pd.read_csv(bp + '{}/{}.txt'.format(fold, gr), sep='\\s+', header=None, usecols=cols)\n",
    "        print(fold, gr, df.shape)\n",
    "        \n",
    "        X, y, qid = split_X_y_qid(df)\n",
    "        print('Split done!')\n",
    "        npz_dict['X_'+gr] = X.values\n",
    "        npz_dict['y_'+gr] = y.values\n",
    "        npz_dict['qid_'+gr] = qid.values\n",
    "    np.savez(file=bp+dirname+fold, **npz_dict)\n",
    "        \n",
    "        \n",
    "#         sort_qid(df)\n",
    "#         df = adjust_features(df, cols)\n",
    "#         df.to_csv(bp + '{}/{}_{}.csv'.format(fold, gr, output_postfix), index=False, sep=' ', header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSLR data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2270296, 138) (747218, 138) (753611, 138)\n",
      "3771125\n",
      "CPU times: user 2min 38s, sys: 10.8 s, total: 2min 49s\n",
      "Wall time: 2min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_df = pd.read_csv('/data/khodadaa/mslr/MSLR-WEB30K/Fold1/train.txt', header=None, sep='\\s+')\n",
    "valid_df = pd.read_csv('/data/khodadaa/mslr/MSLR-WEB30K/Fold1/vali.txt', header=None, sep='\\s+')\n",
    "test_df = pd.read_csv('/data/khodadaa/mslr/MSLR-WEB30K/Fold1/test.txt', header=None, sep='\\s+')    \n",
    "print(train_df.shape, valid_df.shape, test_df.shape)\n",
    "print(train_df.shape[0]+ valid_df.shape[0]+test_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_column_to_score():\n",
    "    mapping = {}\n",
    "    corpus_type = ['bdy', 'anc', 'ttl', 'url', 'wdc']\n",
    "    metric = ['CovQTNum', 'CovQTR', 'StrmLen', 'idf', 'sum-tf', 'min-tf', 'max-tf', 'mean-tf', 'var-tf', \n",
    "          'sum-StrLen-norm-tf', 'min-StrLen-norm-tf', 'max-StrLen-norm-tf', 'mean-StrLen-norm-tf', 'var-StrLen-norm-tf',\n",
    "          'sum-tfidf', 'min-tfidf', 'max-tfidf', 'mean-tfidf', 'var-tfidf', 'boolModel', 'VecSpacMod', 'BM25',\n",
    "          'LMIR.ABS', 'LMIR.DIR', 'LMIR.JM']\n",
    "    i = 0    \n",
    "    for m in metric:\n",
    "        for ct in corpus_type:\n",
    "            i += 1\n",
    "            mapping[i] = m + '({})'.format(ct)\n",
    "\n",
    "    for e in ['NumSlshURL', 'url-len', 'inlink-num', 'outlink-num', 'PageRank', 'SiteRank', 'QualScore',\n",
    "              'QualScore2', 'QUrlCliCnt', 'UrlCliCnt', 'UrlDwellTime']:\n",
    "        i += 1\n",
    "        mapping[i] = e \n",
    "    return mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 47.2 s, sys: 10.6 s, total: 57.8 s\n",
      "Wall time: 31.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_orig = train_df.append(valid_df, ignore_index=True).append(test_df, ignore_index=True)\n",
    "df_orig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df = split_fea_name_val(df_orig)\n",
    "df.sort_values(by=['qid', 'rel'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16min 23s, sys: 46.8 s, total: 17min 10s\n",
      "Wall time: 16min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df.to_csv('/data/khodadaa/mslr/MSLR-WEB30K/mslr-web30k.csv')\n",
    "df_rn = df.rename(columns=map_column_to_score())\n",
    "df_rn.to_csv('/data/khodadaa/mslr/MSLR-WEB30K/mslr-web30k-colname.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn to rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyltr\n",
    "\n",
    "bp = '/data/khodadaa/mslr/MSLR-WEB10K/Fold1'\n",
    "stp_after = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 44s, sys: 3.46 s, total: 3min 48s\n",
      "Wall time: 3min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with open(bp + '/train.txt') as trainfile, \\\n",
    "     open(bp + '/vali.txt') as valifile, \\\n",
    "     open(bp + '/test.txt') as evalfile:\n",
    "        TX, Ty, Tqids, _ = pyltr.data.letor.read_dataset(trainfile)\n",
    "        VX, Vy, Vqids, _ = pyltr.data.letor.read_dataset(valifile)\n",
    "        EX, Ey, Eqids, _ = pyltr.data.letor.read_dataset(evalfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = pyltr.metrics.NDCG(k=10)\n",
    "monitor = pyltr.models.monitors.ValidationMonitor(\n",
    "        VX, Vy, Vqids, metric=metric, stop_after=stp_after)\n",
    "model = pyltr.models.LambdaMART(\n",
    "        metric=metric,\n",
    "        n_estimators=1000,\n",
    "        learning_rate=0.02,\n",
    "        max_features=0.5,\n",
    "        query_subsample=0.5,\n",
    "        max_leaf_nodes=10,\n",
    "        min_samples_leaf=64,\n",
    "        verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Iter  Train score  OOB Improve    Remaining                           Monitor Output \n",
      "    1       0.0348       0.0294      570.62m      C:      0.0343 B:      0.0343 S:  0\n",
      "    2       0.0834       0.0469      562.10m      C:      0.0874 B:      0.0874 S:  0\n",
      "    3       0.2343       0.1494      558.47m      C:      0.2357 B:      0.2357 S:  0\n",
      "    4       0.2736       0.0429      559.88m      C:      0.2755 B:      0.2755 S:  0\n",
      "    5       0.2828       0.0088      555.48m      C:      0.2838 B:      0.2838 S:  0\n",
      "    6       0.3029       0.0225      554.74m      C:      0.3028 B:      0.3028 S:  0\n",
      "    7       0.3316       0.0219      555.91m      C:      0.3317 B:      0.3317 S:  0\n",
      "    8       0.3369       0.0025      557.38m      C:      0.3340 B:      0.3340 S:  0\n",
      "    9       0.3381       0.0010      555.81m      C:      0.3353 B:      0.3353 S:  0\n",
      "   10       0.3320      -0.0003      554.89m      C:      0.3358 B:      0.3358 S:  0\n",
      "   15       0.3431       0.0026      553.52m      C:      0.3451 B:      0.3451 S:  0\n",
      "   20       0.3508      -0.0000      552.64m      C:      0.3506 B:      0.3514 S:  2\n",
      "   25       0.3510       0.0001      550.07m      C:      0.3556 B:      0.3559 S:  3\n",
      "   30       0.3626      -0.0001      550.05m      C:      0.3591 B:      0.3591 S:  0\n",
      "   35       0.3591       0.0010      549.07m      C:      0.3600 B:      0.3600 S:  0\n",
      "   40       0.3563       0.0001      550.32m      C:      0.3605 B:      0.3605 S:  2\n",
      "   45       0.3634      -0.0005      548.77m      C:      0.3614 B:      0.3622 S:  1\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(TX, Ty, Tqids, monitor=monitor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frequency():\n",
    "    test_df = pd.read_csv(bp + '/test.txt', sep='\\s+', header=None)\n",
    "    url_click_counts = test_df[136].str.replace('135:', '')\n",
    "    url_click_counts = url_click_counts.astype(int)\n",
    "    return url_click_counts.values\n",
    "    \n",
    "Epred = model.predict(EX)\n",
    "Efreq = get_frequency()\n",
    "pd.DataFrame({'Eqids': Eqids, 'Ey':Ey, 'Epred':Epred, 'Efreq':Efreq}, \n",
    "                       columns=['Eqids', 'Efreq', 'Ey', 'Epred']).to_csv(\n",
    "                        '{}/lambda_preds_{}.csv'.format(bp, stp_after), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random ranking: 0.18912831330223595\n",
      "Our model: 0.435418749785479\n"
     ]
    }
   ],
   "source": [
    "print('Random ranking:', metric.calc_mean_random(Eqids, Ey))\n",
    "print('Our model:', metric.calc_mean(Eqids, Ey, Epred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cache size effect on test scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cache_score_distrib(df: pd.DataFrame, metric_type='NDCG', local=False, k=10):    \n",
    "    def get_metric(m_type, k):\n",
    "        m = None\n",
    "        if m_type == 'NDCG':\n",
    "            m = pyltr.metrics.NDCG(k=k)\n",
    "        elif m_type == 'DCG':\n",
    "            m = pyltr.metrics.DCG(k=k)\n",
    "        return m\n",
    "    \n",
    "    metric = get_metric(metric_type, k)\n",
    "    df = df.sort_values(by='Efreq', ascending=False)\n",
    "    distrib = pd.Series()    \n",
    "    for i in range(100,0,-1):\n",
    "        if local:\n",
    "            metric = get_metric(metric_type, k)\n",
    "        sz = int((i/100) * df.shape[0])        \n",
    "        ts = df[:sz].sort_values(by='Eqids')\n",
    "        distrib.loc[i] = metric.calc_mean(qids=ts['Eqids'].values, targets=ts['Ey'].values, preds=ts['Epred'].values)    \n",
    "    return distrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.read_csv('/data/khodadaa/mslr/MSLR-WEB10K/Fold1/lambda_preds_10.csv', \n",
    "                      dtype={'Eqids': str, 'Efreq': int, 'Ey': float, 'Epred': float})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "mslr_cache_distribs = pd.DataFrame(index=list(range(1,101)))\n",
    "mslr_cache_distribs['NDCG-global'] = get_cache_score_distrib(pred_df, metric_type='NDCG')\n",
    "mslr_cache_distribs['NDCG-local'] = get_cache_score_distrib(pred_df, metric_type='NDCG', local=True)\n",
    "mslr_cache_distribs['DCG-global'] = get_cache_score_distrib(pred_df, metric_type='DCG')\n",
    "mslr_cache_distribs['DCG-local'] = get_cache_score_distrib(pred_df, metric_type='DCG', local=True)\n",
    "mslr_cache_distribs.to_csv('/data/khodadaa/mslr/MSLR-WEB10K/Fold1/cache_scoring_distributions.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
